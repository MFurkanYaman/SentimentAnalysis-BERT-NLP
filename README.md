BERT Tokenizer: Preprocesses text using the BERT tokenizer for advanced language modeling.

Sentiment Analysis: Classifies texts as positive or negative.

Training Data: This model has been trained using data from https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip.
